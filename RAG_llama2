{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8789580,"sourceType":"datasetVersion","datasetId":5284352}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install --upgrade --quiet langchain langchain_community transformers sentence_transformers chromadb accelerate einops xformers bitsandbytes pymupdf ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T03:05:33.575670Z","iopub.execute_input":"2024-06-27T03:05:33.576428Z","iopub.status.idle":"2024-06-27T03:05:52.614476Z","shell.execute_reply.started":"2024-06-27T03:05:33.576391Z","shell.execute_reply":"2024-06-27T03:05:52.613247Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom langchain.llms import HuggingFacePipeline\nfrom torch import cuda, bfloat16\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\nfrom langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:05:59.233993Z","iopub.execute_input":"2024-06-27T03:05:59.235107Z","iopub.status.idle":"2024-06-27T03:05:59.242137Z","shell.execute_reply.started":"2024-06-27T03:05:59.235063Z","shell.execute_reply":"2024-06-27T03:05:59.241210Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class LLMConfig:\n  def __init__(self):\n    self.model_id = 'meta-llama/Llama-2-7b-chat-hf'\n    self.device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n    self.hf_auth = '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'\n    self.task = 'text-generation'\n    self.temperature = 1\n    self.max_new_tokens = 512\n    self.repetition_penalty = 1.2\n\nclass BuildLLM:\n  def __init__(self) -> None:\n    self.config = LLMConfig()\n    model_id = self.config.model_id\n    device = self.config.device\n    hf_auth = self.config.hf_auth\n\n    bnb_config = transformers.BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_compute_dtype=bfloat16\n    )\n\n    model_config = transformers.AutoConfig.from_pretrained(\n        model_id,\n        use_auth_token=hf_auth\n    )\n\n    model = transformers.AutoModelForCausalLM.from_pretrained(\n        model_id,\n        trust_remote_code=True,\n        config=model_config,\n        quantization_config=bnb_config,\n        device_map='auto',\n        use_auth_token=hf_auth\n    )\n\n    tokenizer = transformers.AutoTokenizer.from_pretrained(\n        model_id,\n        use_auth_token=hf_auth\n    )\n\n    generate_text = transformers.pipeline(\n        model=model,\n        tokenizer=tokenizer,\n        return_full_text=True,\n        task=self.config.task,\n        temperature=self.config.temperature,\n        max_new_tokens=self.config.max_new_tokens,\n        repetition_penalty=self.config.repetition_penalty\n    )\n\n    self.llm = HuggingFacePipeline(pipeline=generate_text)\n  def get_llm(self):\n    return self.llm","metadata":{"execution":{"iopub.status.busy":"2024-06-27T02:41:49.886720Z","iopub.execute_input":"2024-06-27T02:41:49.887600Z","iopub.status.idle":"2024-06-27T02:41:49.897987Z","shell.execute_reply.started":"2024-06-27T02:41:49.887564Z","shell.execute_reply":"2024-06-27T02:41:49.896972Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"llm_builder = BuildLLM()\nllm = llm_builder.get_llm()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T02:41:51.278061Z","iopub.execute_input":"2024-06-27T02:41:51.278422Z","iopub.status.idle":"2024-06-27T02:42:00.977954Z","shell.execute_reply.started":"2024-06-27T02:41:51.278395Z","shell.execute_reply":"2024-06-27T02:42:00.976915Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf3859bd55f4960b9c9188b4e946712"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = DirectoryLoader('/kaggle/input/ragdata/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\ndocuments = loader.load()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:09:29.896899Z","iopub.execute_input":"2024-06-27T03:09:29.897379Z","iopub.status.idle":"2024-06-27T03:09:30.807198Z","shell.execute_reply.started":"2024-06-27T03:09:29.897340Z","shell.execute_reply":"2024-06-27T03:09:30.806378Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\nall_splits = text_splitter.split_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:09:30.808790Z","iopub.execute_input":"2024-06-27T03:09:30.809102Z","iopub.status.idle":"2024-06-27T03:09:30.818273Z","shell.execute_reply.started":"2024-06-27T03:09:30.809064Z","shell.execute_reply":"2024-06-27T03:09:30.817356Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"embedding_model = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:13:14.315612Z","iopub.execute_input":"2024-06-27T03:13:14.316056Z","iopub.status.idle":"2024-06-27T03:13:20.200634Z","shell.execute_reply.started":"2024-06-27T03:13:14.316020Z","shell.execute_reply":"2024-06-27T03:13:20.199738Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n  warn_deprecated(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad6240565284a2d90f8a4e5a07eadf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e86c8b4638c447d8d1ec7126ce57f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881c40eaaf644072a1f15543455bafe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb3dd01fd634eff96d2eb6a46e9b1a5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af5693b5d0bd4440b6d28874a56dcfda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010bd31cf697412ebfd803693b109953"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb889970f024735b28ec73c1fd2842f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06a94ce575948d3a86e2da423ef6bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53fab5a07914178937662eb34a5d816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b79ee9dc1a41c7a42cb78de09be1fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad77d78e00b4be69e55602d7dedbbda"}},"metadata":{}}]},{"cell_type":"code","source":"vectordb = Chroma.from_documents(documents=documents, embedding=embedding_model, persist_directory=\"chroma_db\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:17:15.979797Z","iopub.execute_input":"2024-06-27T03:17:15.980745Z","iopub.status.idle":"2024-06-27T03:17:19.690891Z","shell.execute_reply.started":"2024-06-27T03:17:15.980708Z","shell.execute_reply":"2024-06-27T03:17:19.689998Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\nqa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:19:44.134333Z","iopub.execute_input":"2024-06-27T03:19:44.134852Z","iopub.status.idle":"2024-06-27T03:19:44.143773Z","shell.execute_reply.started":"2024-06-27T03:19:44.134812Z","shell.execute_reply":"2024-06-27T03:19:44.142515Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query:\\n{query}\\n\")\n    result = qa.invoke(query)\n    print(f\"Result:\\n{result['result']}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:28:28.200571Z","iopub.execute_input":"2024-06-27T03:28:28.201465Z","iopub.status.idle":"2024-06-27T03:28:28.206651Z","shell.execute_reply.started":"2024-06-27T03:28:28.201426Z","shell.execute_reply":"2024-06-27T03:28:28.205627Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"query = \"How to characterize the trade-off between hallucination and creativity?\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T03:28:29.865504Z","iopub.execute_input":"2024-06-27T03:28:29.865876Z","iopub.status.idle":"2024-06-27T03:28:56.487665Z","shell.execute_reply.started":"2024-06-27T03:28:29.865847Z","shell.execute_reply":"2024-06-27T03:28:56.486551Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Query:\nHow to characterize the trade-off between hallucination and creativity?\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nResult:\nUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nMathematics 2023 ,11, 2320 14 of 17\nEstablishing an ideal equilibrium between hallucination and creativity is vital for the\nmodel’s effectiveness in a wide range of applications. The problem below encapsulates\nthis concept.\nProblem 1. LetM(α)represent a collection of GPT models parameterized by a trade-off parameter\nα, and letP(Θ)denote the performance metric as deﬁned in (21). The optimization problem involves\nidentifying the optimal trade-off parameter α∗that maximizes the performance metric:\nα∗=arg max\nα∈[0,1]P(Θ). (31)\nRemark 10. Optimizing the trade-off parameter in Problem 1 proves difﬁcult due to the vast\nparameter space of GPT models and the potential nonconvexity of the performance metric P(Θ).\nConjecture 3. The performance metric P(Θ)might present multiple local optima associated with\ndistinct values of α, each signifying a unique equilibrium between hallucination and creativity.\nConsidering the intricacy of the optimization landscape, it is crucial to explore efﬁcient\nmethods to examine the interplay between hallucination and creativity. One feasible ap-\nproach is to utilize meta-learning techniques that adaptively update the trade-off parameter\nαduring training, consequently enabling the model to learn the optimal equilibrium.\nExample 3. A meta-learning algorithm can iteratively update the trade-off parameter αbased on the\nmodel’s performance on a validation set. The algorithm may employ methods such as gradient-based\noptimization or Bayesian optimization to effectively search for the optimal αvalue.\nAnother avenue for future research is to investigate the impact of model architecture\nand training techniques on the trade-off between hallucination and creativity. For instance,\nit may be possible to design novel self-attention mechanisms or regularization techniques\nthat explicitly encourage the model to maintain a balance between generating plausible yet\ncreative responses.\nExample 4. The development of an attention mechanism that explicitly models the relationship\nbetween the input and output tokens could potentially improve the balance between hallucination\nand creativity. Such a mechanism could be designed to assign higher importance to relevant tokens\nin the input while penalizing the generation of implausible tokens.\nProblem 2. Investigate the characteristics of the optimal trade-off parameter α∗and its associated\nlocal optima, in relation to the GPT model’s performance across a variety of tasks.\nProposition 9. The optimal trade-off parameter α∗may be inﬂuenced by the particular task\nrequirements and the structure of the input data.\nIn order to tackle the task-speciﬁc dependencies, adopting an adaptive strategy for\nﬁne-tuning the trade-off parameter αmay contribute to enhanced performance.\nAssumption 12. Modifying the trade-off parameter αdepending on the particular task and input\ndata can lead to superior GPT model performance.\nAs a result, devising an adaptive method for dynamically ﬁne-tuning the trade-off\nparameter αbecomes an essential research focus.\nProblem 3. Create an adaptive method to dynamically modify the trade-off parameter αin GPT\nmodels based on task demands and input data.\n\nMathematics 2023 ,11, 2320 12 of 17\nProposition 8. Under Assumption 10, the creativity of GPT models, as measured by the normalized\nentropy in (19), will be higher in the presence of the hallucination phenomenon.\nProof. According to Lemma 1, the generation of low-probability tokens in GPT models is\nassociated with high uncertainty , as measured by the entropy in (17). Under Assumption 10 ,\nthis increased entropy also implies a higher level of creativity, as given by (19). There-\nfore, the creativity of GPT models will be higher in the presence of the hallucination\nphenomenon.\nConjecture 1. There exists an optimal trade-off between hallucination and creativity in GPT\nmodels, such that the model’s performance is maximized when operating at this trade-off point.\nConsidering Conjecture 1, we seek to characterize the optimal trade-off between\nhallucination and creativity in GPT models. Speciﬁcally, we consider a parametric family of\nmodels, where each model is tuned to balance hallucination and creativity differently. Let\nM(α)denote a GPT model parametrized by α∈[0, 1]. The parameter αcontrols the trade-\noff between hallucination and creativity, with α=0corresponding to a purely hallucination-\nminimizing model and α=1 corresponding to a purely creativity-maximizing model.\nDeﬁnition 5. LetM(α)be a GPT model parametrized by α∈[0, 1]. We deﬁne the hallucination–\ncreativity trade-off parameter αas the weighting factor that balances the contribution of the\nhallucination-related prediction error and the creativity of the model in the model’s objective function:\nJ(Θ,α) =( 1−α)·E(x1,...,xn)∼Ptrue[DKL(Ptrue(xi+1|x1,x2, . . . , xi)||Pmodel(xi+1|x1,x2, . . . , xi;Θ))]\n−α·E(x1,...,xn)∼Ptrue[C(xi+1|x1,x2, . . . , xi;Θ)], (20)\nwhere D KLdenotes the KL divergence and C denotes the creativity measure as deﬁned in (19).\nOur goal is to ﬁnd the optimal value of the trade-off parameter α∗that maximizes\nthe model’s performance, as measured by a suitable performance metric. To this end, we\nintroduce the following performance metric:\nDeﬁnition 6. LetPtask(xi+1|x1,x2,. . .,xi)denote the probability distribution of the next token in\nthe sequence, as conditioned on the speciﬁc task requirements. The performance metric of a GPT\nmodel is deﬁned as the expected KL divergence between the task-speciﬁc distribution and the model’s\npredicted distribution:\nP(Θ) =E(x1,...,xn)∼Ptask[DKL(Ptask(xi+1|x1,x2, . . . , xi)||Pmodel(xi+1|x1,x2, . . . , xi;Θ))]. (21)\nConjecture 2. There exists an optimal trade-off parameter α∗∈[0, 1]that maximizes the perfor-\nmance metricP(Θ)for GPT models, as deﬁned in (21).\nConsider the optimization problem of ﬁnding the optimal trade-off parameter α∗that\nmaximizes the performance metric P(Θ):\nα∗=arg max\nα∈[0,1]P(Θ). (22)\nTo solve (22), we ﬁrst examine the relationship between the objective function J(Θ,α)\nin (20) and the performance metric P(Θ)in (21).\nFor a ﬁxed Θ, the objective function can be written as follows:\nJ(Θ,α) = ( 1−α)·Jhallucination (Θ)−α·Jcreativity (Θ), (23)\nwhere Jhallucination (Θ)and Jcreativity (Θ)represent the hallucination-related prediction error\nand the creativity of the model, respectively.\n\nMathematics 2023 ,11, 2320 13 of 17\nExample 2. To illustrate the role of the compromise parameter α, let us consider an example in\nwhich a GPT model is generating text for a storytelling task. In this scenario, a high αvalue would\nprioritize minimizing the hallucination-related prediction error, potentially resulting in a more\nconservative and contextually plausible output. However, this output might lack originality and\nvariety, which are essential for a compelling story. On the other hand, a low αvalue would emphasize\ncreativity, leading to a more diverse and original output. However, this might come at the expense\nof increased hallucination and reduced contextual plausibility. The optimal trade-off parameter\nα∗represents a balance between these competing objectives, yielding an output that exhibits both\ncreativity and contextual plausibility while minimizing hallucinations.\nWe analyze the derivative of J(Θ,α)with respect to α:\ndJ(Θ,α)\ndα=−Jhallucination (Θ) +Jcreativity (Θ). (24)\nBy settingdJ(Θ,α)\ndα=0, we can ﬁnd the critical points of the objective function:\nJhallucination (Θ) = Jcreativity (Θ). (25)\nThe critical points correspond to the trade-off points where the hallucination-related\nprediction error is balanced with the creativity of the model. To ﬁnd the optimal trade-off\npoint α∗, we need to analyze the second derivative of J(Θ,α)with respect to α:\nd2J(Θ,α)\ndα2=0. (26)\nSince the second derivative is always zero, we cannot directly determine the concavity\nor convexity of the objective function. Thus, we need to further investigate the relationship\nbetween the objective function and the performance metric.\nIn (21), the KL divergence is always non-negative, and we can conclude that P(Θ)is\nminimized when the model’s predictions align with the task-speciﬁc probability distribution:\nPtask(xi+1|x1,x2, . . . , xi)≈Pmodel(xi+1|x1,x2, . . . , xi;Θ). (27)\nTo analyze the optimal trade-off between hallucination and creativity, we investigate\nthe behavior of the performance metric P(Θ)as a function of the trade-off parameter α.\nWe ﬁrst derive the gradient of P(Θ)with respect to Θ:\n∇ΘP(Θ) =E(x1,...,xn)∼Ptask[∇ΘDKL(Ptask(xi+1|x1,x2, . . . , xi)||Pmodel(xi+1|x1,x2, . . . , xi;Θ))]. (28)\nBy plugging (27) into (28), we can express the gradient of the performance metric as a\nfunction of the trade-off parameter α:\n∇ΘP(Θ,α) =E(x1,...,xn)∼Ptask[\n∇ΘDKL(Ptask(xi+1|x1,x2, . . . , xi)||PM(α)(xi+1|x1,x2, . . . , xi;Θ))]\n. (29)\nTo ﬁnd the optimal trade-off parameter α∗, we need to solve the following optimiza-\ntion problem:\nα∗=arg min\nα∈[0,1]∇ΘP(Θ,α). (30)\nSince the optimization problem in (30) is nonconvex and the gradient of the perfor-\nmance metric with respect to Θdepends on the trade-off parameter α, we resort to a\ngradient-based optimization method to ﬁnd the optimal trade-off parameter α∗.\n3.3. Examining the Interplay between Hallucination and Creativity\nAssumption 11. The efﬁcacy of GPT models across various tasks hinges on the delicate equilibrium\nbetween hallucination and creativity. Adjusting this equilibrium may potentially improve the overall\nperformance of the model.\n\nMathematics 2023 ,11, 2320 10 of 17\nTherefore, under Assumption 8, the occurrence of hallucinations in a well-trained\nGPT model is strongly correlated with the model’s uncertainty, as captured by the entropy\nin (17).\nHere, we demonstrate how the hallucination in GPT models can be reinforced by\nusing the selected token as input for estimating the subsequent tokens, and how this\nreinforcement can lead to a series of hallucinations in the generated text. We approach this\nproblem by analyzing the conditional probabilities of generating subsequent tokens given\nthe context and the previously generated tokens.\nAssumption 9. The probability of generating a hallucinatory token xi+1at position i+1is\nconditionally independent of generating a hallucinatory token xi+2at position i+2, given the\ncontext up to position i.\nUnder Assumption 9, we can now analyze the reinforcement of hallucination in GPT\nmodels. Let H(xi+1)denote the event that the generated token xi+1is hallucinatory, and let\np(H(xi+1)|x1,x2,. . .,xi;Θ)denote the conditional probability of generating a hallucinatory\ntoken xi+1given the context up to position i.\nProposition 6. The probability of generating a hallucinatory token xi+2at position i+2, condi-\ntioned on generating a hallucinatory token x i+1at position i +1, is given by\np(H(xi+2)|H(xi+1),x1,x2, . . . , xi;Θ) =p(H(xi+2),H(xi+1)|x1,x2, . . . , xi;Θ)\np(H(xi+1)|x1,x2, . . . , xi;Θ). (18)\nLetR=p(H(xi+2)|H(xi+1),x1,x2,. . .,xi;Θ). IfR>p(H(xi+2)|x1,x2,. . .,xi;Θ), then\ngenerating a hallucinatory token xi+1increases the likelihood of generating a hallucinatory\ntoken xi+2.\nTheorem 3. If the conditional probability Rsatisﬁes R>p(H(xi+2)|x1,x2,. . .,xi;Θ), then\ngenerating a hallucinatory token xi+1increases the likelihood of generating a hallucinatory token\nxi+2, leading to the reinforcement of hallucination in GPT models.\nProof. Under Assumption 9, we have\np(H(xi+2),H(xi+1)|x1,x2, . . . , xi;Θ) =p(H(xi+2)|H(xi+1),x1,x2, . . . , xi;Θ)\n·p(H(xi+1)|x1,x2, . . . , xi;Θ)\n=R·p(H(xi+1)|x1,x2, . . . , xi;Θ).\nNow, we can express the joint probability of generating hallucinatory tokens xi+1and\nxi+2as\np(H(xi+2),H(xi+1)|x1,x2, . . . , xi;Θ) =R·p(H(xi+1)|x1,x2, . . . , xi;Θ).\nIfR>p(H(xi+2)|x1,x2, . . . , xi;Θ), then\np(H(xi+2),H(xi+1)|x1,x2, . . . , xi;Θ)>p(H(xi+2)|x1,x2, . . . , xi;Θ)·p(H(xi+1)|x1,x2, . . . , xi;Θ),\nwhich implies that generating a hallucinatory token xi+1increases the likelihood of generat-\ning a hallucinatory token xi+2. This reinforcement effect can cascade through the generated\ntext, leading to a series of hallucinations in GPT models.\nRemark 7. The risk of reinforcement of hallucination depends on the conditional probability R. If the\nGPT model generates a hallucinatory token xi+1, the likelihood of generating a hallucinatory token\nxi+2increases when R>p(H(xi+2)|x1,x2,. . .,xi;Θ). This reinforcement effect can propagate\nthrough the generated text, exacerbating the hallucination phenomenon.\n\nQuestion: How to characterize the trade-off between hallucination and creativity?\nHelpful Answer: By understanding the nature of the objective function J(θ, α)in (20)\nand the performance metric P(θ)in (21), one can develop effective methods to adjust the trade-off\nparameter αto strike a desired balance between hallucination and creativity in GPT models.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}